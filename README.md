📘 Neuron-Level Phoneme Explanation Using WavLM
Welcome to the official codebase for the research project:
“Neuron-Level Phoneme Explanation Using WavLM”

This project aims to interpret the inner workings of WavLM, a state-of-the-art self-supervised speech model, by probing how individual neurons across layers encode phonetic features such as voicing, frication, and nasality.

📌 Key Objectives
🔍 Train simple classifiers to probe phonetic features at each WavLM layer.

🧠 Analyze neuron-level importance using Integrated Gradients (IG).

