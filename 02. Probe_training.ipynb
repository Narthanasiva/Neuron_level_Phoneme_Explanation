{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNsN0RJwvDzDXA++eP19NjA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Step 01: Setup Google Drive and Imports**"],"metadata":{"id":"Z7J_uaS392xk"}},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bTJX555X91jk","executionInfo":{"status":"ok","timestamp":1747885447908,"user_tz":-330,"elapsed":3064,"user":{"displayName":"Narthana Sivalingam","userId":"13596974493535450845"}},"outputId":"fcc1b557-7cbe-4a0b-c2a6-9af17c5ce9e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import pandas as pd\n","import json\n","import os\n","from pathlib import Path\n","from typing import Tuple\n","import numpy as np\n"],"metadata":{"id":"2d-jB13v-5hK","executionInfo":{"status":"ok","timestamp":1747885505063,"user_tz":-330,"elapsed":5,"user":{"displayName":"Narthana Sivalingam","userId":"13596974493535450845"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# ============ CONFIG ============\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","EPOCHS = 15\n","BATCH_SIZE = 512\n","LR = 1e-3\n","FEATURES = [\"voiced\", \"fricative\", \"nasal\"]\n","NUM_LAYERS = 13\n","EMB_DIM = 768  # WavLM embedding size\n","HIDDEN_DIM = 200\n","\n","\n","\n","# ============ PATHS =============\n","\n","# Paths for dataset and results\n","ROOT_DIR = \"/content/drive/MyDrive/00_RESEARCH_MSC_00/Final_Phonetic_Identification\"\n","DATA_DIR = f\"{ROOT_DIR}/01_layer_datasets\"\n","MODEL_DIR = f\"{ROOT_DIR}/02_Trained_models\"\n","METRIC_DIR = f\"{ROOT_DIR}/03_Evaluation_metrics_of_probes\"\n","\n","# Create output folders if they don't exist\n","import os\n","os.makedirs(MODEL_DIR, exist_ok=True)\n","os.makedirs(METRIC_DIR, exist_ok=True)"],"metadata":{"id":"wryXKy1m-ENC","executionInfo":{"status":"ok","timestamp":1747885453721,"user_tz":-330,"elapsed":17,"user":{"displayName":"Narthana Sivalingam","userId":"13596974493535450845"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# **Step 02: Define the PyTorch MLP Model**"],"metadata":{"id":"a8-kFGeY-86e"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class MLPProbe(nn.Module):\n","    \"\"\"\n","    One-hidden-layer MLP probe: 768 → 200 → 1 (with sigmoid)\n","    \"\"\"\n","    def __init__(self, input_dim=EMB_DIM, hidden_dim=HIDDEN_DIM):\n","        super(MLPProbe, self).__init__()\n","        self.hidden = nn.Linear(input_dim, hidden_dim)\n","        self.output = nn.Linear(hidden_dim, 1)\n","        self.relu = nn.ReLU()\n","        self.sigmoid = nn.Sigmoid()  # Used only for inference\n","\n","    def forward(self, x):\n","        x = self.hidden(x)\n","        x = self.relu(x)\n","        x = self.output(x)  # No sigmoid here for training (BCEWithLogits)\n","        return x\n","\n"],"metadata":{"id":"3V4-Nmtt_O6Q","executionInfo":{"status":"ok","timestamp":1747885456751,"user_tz":-330,"elapsed":11,"user":{"displayName":"Narthana Sivalingam","userId":"13596974493535450845"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# **Step 3: Load Dataset for a Specific Layer + Feature for training and testing**"],"metadata":{"id":"QKc9wVm_AgFU"}},{"cell_type":"code","source":["def load_dataset(layer: int, feature: str):\n","    \"\"\"\n","    Load training and test data for a specific layer and feature.\n","    \"\"\"\n","    train_df = pd.read_pickle(f\"{DATA_DIR}/layer_{layer}_train.pkl\")\n","    test_df = pd.read_pickle(f\"{DATA_DIR}/layer_{layer}_test.pkl\")\n","\n","    X_train = torch.tensor(np.stack(train_df[\"embedding\"]), dtype=torch.float32)\n","    X_test  = torch.tensor(np.stack(test_df[\"embedding\"]), dtype=torch.float32)\n","    y_train = torch.tensor(train_df[feature].values, dtype=torch.float32).unsqueeze(1)\n","    y_test  = torch.tensor(test_df[feature].values, dtype=torch.float32).unsqueeze(1)\n","\n","    return X_train.to(DEVICE), y_train.to(DEVICE), X_test.to(DEVICE), y_test.to(DEVICE)\n"],"metadata":{"id":"5OQXmVWW_knU","executionInfo":{"status":"ok","timestamp":1747885459365,"user_tz":-330,"elapsed":14,"user":{"displayName":"Narthana Sivalingam","userId":"13596974493535450845"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# **Step 4: Train the MLP Model**"],"metadata":{"id":"qJUa9BEXA0sy"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","def train_model(model: nn.Module,\n","                X_train: torch.Tensor,\n","                y_train: torch.Tensor,\n","                epochs: int = 25,\n","                batch_size: int = 512,\n","                lr: float = 1e-3) -> nn.Module:\n","    \"\"\"\n","    Trains a 1-hidden-layer MLP binary classifier using PyTorch.\n","\n","    Parameters:\n","    -----------\n","    model : nn.Module\n","        The MLP model to be trained (input → hidden → output).\n","\n","    X_train : torch.Tensor\n","        Training features (shape: [num_samples, 768]).\n","\n","    y_train : torch.Tensor\n","        Binary labels (shape: [num_samples, 1]), values 0 or 1.\n","\n","    epochs : int\n","        Number of training epochs (full passes over the dataset).\n","\n","    batch_size : int\n","        Number of samples per mini-batch.\n","\n","    lr : float\n","        Learning rate for the Adam optimizer.\n","\n","    Returns:\n","    --------\n","    model : nn.Module\n","        The trained model with updated weights.\n","    \"\"\"\n","\n","    # Loss function: Binary cross-entropy with sigmoid built-in\n","    criterion = nn.BCEWithLogitsLoss()\n","\n","    # Optimizer: Adam adjusts learning based on gradients\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","    # Combine input features and labels into a single dataset\n","    dataset = TensorDataset(X_train, y_train)\n","\n","    # Load the dataset in mini-batches (shuffled for better learning)\n","    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","    # Set model in training mode (important for things like dropout or batchnorm)\n","    model.train()\n","\n","    # Enable gradient calculation (required during training)\n","    with torch.set_grad_enabled(True):\n","        # Loop over the number of full passes over the dataset\n","        for epoch in range(epochs):\n","            total_loss = 0  # Keep track of total loss in this epoch\n","\n","            # Go through the dataset in mini-batches\n","            for xb, yb in dataloader:\n","                optimizer.zero_grad()        # Reset gradients from the last step\n","                logits = model(xb)           # Forward pass: get raw predictions (logits)\n","                loss = criterion(logits, yb) # Calculate loss between prediction and truth\n","                loss.backward()              # Backward pass: compute gradients\n","                optimizer.step()             # Update weights using gradients\n","\n","                total_loss += loss.item()    # Track total loss\n","\n","            # Print average loss for this epoch\n","            avg_loss = total_loss / len(dataloader)\n","            print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n","\n","    return model  # Return the trained model\n"],"metadata":{"id":"bDfAQ1fnAzvE","executionInfo":{"status":"ok","timestamp":1747885461773,"user_tz":-330,"elapsed":10,"user":{"displayName":"Narthana Sivalingam","userId":"13596974493535450845"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# **Step 5: Evaluate the Model**"],"metadata":{"id":"Ny31OQm8GOlX"}},{"cell_type":"code","source":["import torch\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","def evaluate_model(model: torch.nn.Module,\n","                   X_test: torch.Tensor,\n","                   y_test: torch.Tensor) -> dict:\n","    \"\"\"\n","    Evaluates a trained binary classifier on test data and returns key metrics.\n","\n","    Parameters:\n","    -----------\n","    model : nn.Module\n","        The trained PyTorch MLP model.\n","\n","    X_test : torch.Tensor\n","        Test features (shape: [num_samples, 768]).\n","\n","    y_test : torch.Tensor\n","        True binary labels (shape: [num_samples, 1]), values are 0 or 1.\n","\n","    Returns:\n","    --------\n","    metrics : dict\n","        A dictionary containing accuracy, precision, recall, and F1-score.\n","    \"\"\"\n","\n","    # Put the model in evaluation mode (disables dropout, etc.)\n","    model.eval()\n","\n","    # We don’t need to compute gradients during evaluation\n","    with torch.no_grad():\n","        # Get the model's output logits (before sigmoid)\n","        logits = model(X_test)\n","\n","        # Apply sigmoid to get probabilities between 0 and 1\n","        probs = torch.sigmoid(logits)\n","\n","        # Convert probabilities to binary predictions (1 if ≥ 0.5, else 0)\n","        preds = (probs >= 0.5).float()\n","\n","    # Move predictions and labels to CPU so we can use sklearn\n","    y_true = y_test.cpu().numpy().ravel()\n","    y_pred = preds.cpu().numpy().ravel()\n","\n","    # Compute evaluation metrics\n","    accuracy  = accuracy_score (y_true, y_pred)\n","    precision = precision_score(y_true, y_pred, zero_division=0)\n","    recall    = recall_score   (y_true, y_pred, zero_division=0)\n","    f1        = f1_score       (y_true, y_pred, zero_division=0)\n","\n","    # Store all metrics in a dictionary\n","    metrics = {\n","        \"accuracy\": accuracy,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1\": f1\n","    }\n","\n","    # Print them in a readable format\n","    print(f\"📊 Evaluation Results - Acc: {accuracy:.3f}, Prec: {precision:.3f}, \"\n","          f\"Rec: {recall:.3f}, F1: {f1:.3f}\")\n","\n","    return metrics\n"],"metadata":{"id":"KyzjIqcQGQP7","executionInfo":{"status":"ok","timestamp":1747885466131,"user_tz":-330,"elapsed":11,"user":{"displayName":"Narthana Sivalingam","userId":"13596974493535450845"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["# **Step 6: Save Model and Config AND Evaluation metric**"],"metadata":{"id":"3cWB--j2GTaQ"}},{"cell_type":"code","source":["def save_model(model, layer: int, feature: str):\n","    layer_dir = Path(MODEL_DIR) / f\"layer_{layer}\"\n","    layer_dir.mkdir(parents=True, exist_ok=True)\n","\n","    torch.save(model.state_dict(), layer_dir / f\"{feature}_model.pt\")\n","    with open(layer_dir / f\"{feature}_config.json\", \"w\") as f:\n","        json.dump({\"input_dim\": 768, \"hidden_dim\": 200}, f)\n"],"metadata":{"id":"BlzXMz3qGgGg","executionInfo":{"status":"ok","timestamp":1747885469503,"user_tz":-330,"elapsed":9,"user":{"displayName":"Narthana Sivalingam","userId":"13596974493535450845"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def save_metrics(all_metrics: dict, layer: int):\n","    with open(Path(METRIC_DIR) / f\"layer_{layer}_metrics.json\", \"w\") as f:\n","        json.dump(all_metrics, f, indent=2)\n"],"metadata":{"id":"Ei2UqAj9GirZ","executionInfo":{"status":"ok","timestamp":1747885471488,"user_tz":-330,"elapsed":6,"user":{"displayName":"Narthana Sivalingam","userId":"13596974493535450845"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["# **07. Step 07: Create layers vs f1 score/accuracy**"],"metadata":{"id":"gWehn54gqlAo"}},{"cell_type":"code","source":["import pandas as pd\n","from pathlib import Path\n","\n","def save_score_tables(metrics: list, save_dir: Path):\n","    \"\"\"\n","    Creates and saves two CSV files: one for F1 scores and one for accuracy scores.\n","\n","    Parameters:\n","    -----------\n","    metrics : list of dict\n","        The full list of metrics from evaluate_model() with keys:\n","        ['layer', 'feature', 'accuracy', 'f1', ...]\n","\n","    save_dir : Path\n","        Directory to save the CSV files (e.g., METRIC_DIR)\n","    \"\"\"\n","\n","    # Create a list of unique layers and features\n","    layers = sorted(set(m[\"layer\"] for m in metrics))\n","    features = [\"voiced\", \"fricative\", \"nasal\"]\n","\n","    # Initialize empty DataFrames\n","    f1_df = pd.DataFrame(columns=[\"layer\"] + features)\n","    acc_df = pd.DataFrame(columns=[\"layer\"] + features)\n","\n","    # Fill the DataFrames row by row\n","    for L in layers:\n","        row_f1 = {\"layer\": L}\n","        row_acc = {\"layer\": L}\n","        for feat in features:\n","            # Find the matching metric dict\n","            m = next((m for m in metrics if m[\"layer\"] == L and m[\"feature\"] == feat), None)\n","            if m:\n","                row_f1[feat] = round(m[\"f1\"], 4)\n","                row_acc[feat] = round(m[\"accuracy\"], 4)\n","        f1_df = pd.concat([f1_df, pd.DataFrame([row_f1])], ignore_index=True)\n","        acc_df = pd.concat([acc_df, pd.DataFrame([row_acc])], ignore_index=True)\n","\n","    # Save the CSVs\n","    f1_path = save_dir / \"f1_scores.csv\"\n","    acc_path = save_dir / \"accuracy_scores.csv\"\n","    f1_df.to_csv(f1_path, index=False)\n","    acc_df.to_csv(acc_path, index=False)\n","\n","    print(f\"✅ F1 scores saved to: {f1_path}\")\n","    print(f\"✅ Accuracy scores saved to: {acc_path}\")\n"],"metadata":{"id":"ON38I0aEqmu8","executionInfo":{"status":"ok","timestamp":1747885473704,"user_tz":-330,"elapsed":4,"user":{"displayName":"Narthana Sivalingam","userId":"13596974493535450845"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["# **MAIN function**"],"metadata":{"id":"r6MQvAlFG6VS"}},{"cell_type":"code","source":["def main():\n","    # Step 1: Define all 3 phonetic features you're probing\n","    FEATURES = [\"voiced\", \"fricative\", \"nasal\"]\n","\n","    # Directory to save results (customize if needed)\n","    METRIC_DIR = Path(\"/content/drive/MyDrive/00_RESEARCH_MSC_00/Final_Phonetic_Identification/03_Evaluation_metrics_of_probes\")\n","\n","    # Store all metrics for all layers and features\n","    all_metrics = []\n","\n","    # Step 2: Loop over all 13 WavLM layers (0 to 12)\n","    for layer in range(13):\n","        print(f\"\\n🔍 Processing Layer {layer}\")\n","        layer_metrics = {}  # Dictionary to store metrics for all 3 features in this layer\n","\n","        # Step 3: Loop over each binary feature (1 model per feature)\n","        for feature in FEATURES:\n","            print(f\"  ▶ Training for Feature: {feature}\")\n","\n","            # Step 3.1: Load the dataset (X: 768D embeddings, y: 0/1 binary label)\n","            X_train, y_train, X_test, y_test = load_dataset(layer, feature)\n","\n","            # Step 3.2: Initialize a fresh model\n","            model = MLPProbe(input_dim=768, hidden_dim=200)\n","\n","            # Step 3.3: Train the model using the training data\n","            train_model(model, X_train, y_train)\n","\n","            # Step 3.4: Evaluate the trained model using test data\n","            metrics = evaluate_model(model, X_test, y_test)\n","\n","            # Step 3.5: Print the evaluation results\n","            print(f\"     ➤ F1-score: {metrics['f1']:.3f}, Accuracy: {metrics['accuracy']:.3f}\")\n","\n","            # Step 3.6: Save the trained model\n","            save_model(model, layer, feature)\n","\n","            # Step 3.7: Store this feature’s metrics under the layer\n","            layer_metrics[feature] = metrics\n","\n","            # Step 3.8: Add full info to all_metrics (including layer + feature)\n","            metrics_with_meta = metrics.copy()\n","            metrics_with_meta.update({\"layer\": layer, \"feature\": feature})\n","            all_metrics.append(metrics_with_meta)\n","\n","        # Step 4: Save the complete metrics for this layer (all 3 features) as JSON\n","        save_metrics(layer_metrics, layer)\n","\n","    # ✅ FINAL STEP: Save overall F1 and accuracy tables as CSVs\n","    save_score_tables(all_metrics, METRIC_DIR)\n","\n","    print(\"\\n✅ All layers and features have been trained, evaluated, and saved successfully.\")\n"],"metadata":{"id":"ABVaaYv0G9MH","executionInfo":{"status":"ok","timestamp":1747885476757,"user_tz":-330,"elapsed":3,"user":{"displayName":"Narthana Sivalingam","userId":"13596974493535450845"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qoJQ3VSi_zaZ","executionInfo":{"status":"ok","timestamp":1747885714229,"user_tz":-330,"elapsed":203709,"user":{"displayName":"Narthana Sivalingam","userId":"13596974493535450845"}},"outputId":"a7490902-4e9b-4606-a905-2f5d4614ad66"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🔍 Processing Layer 0\n","  ▶ Training for Feature: voiced\n","Epoch 1/25 - Loss: 0.5476\n","Epoch 2/25 - Loss: 0.3047\n","Epoch 3/25 - Loss: 0.2093\n","Epoch 4/25 - Loss: 0.1755\n","Epoch 5/25 - Loss: 0.1585\n","Epoch 6/25 - Loss: 0.1462\n","Epoch 7/25 - Loss: 0.1365\n","Epoch 8/25 - Loss: 0.1291\n","Epoch 9/25 - Loss: 0.1220\n","Epoch 10/25 - Loss: 0.1166\n","Epoch 11/25 - Loss: 0.1110\n","Epoch 12/25 - Loss: 0.1067\n","Epoch 13/25 - Loss: 0.1036\n","Epoch 14/25 - Loss: 0.0981\n","Epoch 15/25 - Loss: 0.0946\n","Epoch 16/25 - Loss: 0.0904\n","Epoch 17/25 - Loss: 0.0861\n","Epoch 18/25 - Loss: 0.0835\n","Epoch 19/25 - Loss: 0.0800\n","Epoch 20/25 - Loss: 0.0770\n","Epoch 21/25 - Loss: 0.0744\n","Epoch 22/25 - Loss: 0.0718\n","Epoch 23/25 - Loss: 0.0693\n","Epoch 24/25 - Loss: 0.0669\n","Epoch 25/25 - Loss: 0.0647\n","📊 Evaluation Results - Acc: 0.871, Prec: 0.859, Rec: 0.909, F1: 0.883\n","     ➤ F1-score: 0.883, Accuracy: 0.871\n","  ▶ Training for Feature: fricative\n","Epoch 1/25 - Loss: 0.5213\n","Epoch 2/25 - Loss: 0.2737\n","Epoch 3/25 - Loss: 0.1888\n","Epoch 4/25 - Loss: 0.1570\n","Epoch 5/25 - Loss: 0.1368\n","Epoch 6/25 - Loss: 0.1261\n","Epoch 7/25 - Loss: 0.1181\n","Epoch 8/25 - Loss: 0.1097\n","Epoch 9/25 - Loss: 0.1026\n","Epoch 10/25 - Loss: 0.0958\n","Epoch 11/25 - Loss: 0.0911\n","Epoch 12/25 - Loss: 0.0848\n","Epoch 13/25 - Loss: 0.0802\n","Epoch 14/25 - Loss: 0.0750\n","Epoch 15/25 - Loss: 0.0704\n","Epoch 16/25 - Loss: 0.0664\n","Epoch 17/25 - Loss: 0.0629\n","Epoch 18/25 - Loss: 0.0593\n","Epoch 19/25 - Loss: 0.0558\n","Epoch 20/25 - Loss: 0.0526\n","Epoch 21/25 - Loss: 0.0495\n","Epoch 22/25 - Loss: 0.0471\n","Epoch 23/25 - Loss: 0.0444\n","Epoch 24/25 - Loss: 0.0416\n","Epoch 25/25 - Loss: 0.0395\n","📊 Evaluation Results - Acc: 0.903, Prec: 0.622, Rec: 0.757, F1: 0.683\n","     ➤ F1-score: 0.683, Accuracy: 0.903\n","  ▶ Training for Feature: nasal\n","Epoch 1/25 - Loss: 0.5358\n","Epoch 2/25 - Loss: 0.2970\n","Epoch 3/25 - Loss: 0.1721\n","Epoch 4/25 - Loss: 0.1123\n","Epoch 5/25 - Loss: 0.0842\n","Epoch 6/25 - Loss: 0.0674\n","Epoch 7/25 - Loss: 0.0581\n","Epoch 8/25 - Loss: 0.0525\n","Epoch 9/25 - Loss: 0.0481\n","Epoch 10/25 - Loss: 0.0456\n","Epoch 11/25 - Loss: 0.0431\n","Epoch 12/25 - Loss: 0.0412\n","Epoch 13/25 - Loss: 0.0386\n","Epoch 14/25 - Loss: 0.0372\n","Epoch 15/25 - Loss: 0.0355\n","Epoch 16/25 - Loss: 0.0342\n","Epoch 17/25 - Loss: 0.0327\n","Epoch 18/25 - Loss: 0.0313\n","Epoch 19/25 - Loss: 0.0304\n","Epoch 20/25 - Loss: 0.0292\n","Epoch 21/25 - Loss: 0.0277\n","Epoch 22/25 - Loss: 0.0266\n","Epoch 23/25 - Loss: 0.0252\n","Epoch 24/25 - Loss: 0.0241\n","Epoch 25/25 - Loss: 0.0232\n","📊 Evaluation Results - Acc: 0.955, Prec: 0.606, Rec: 0.645, F1: 0.625\n","     ➤ F1-score: 0.625, Accuracy: 0.955\n","\n","🔍 Processing Layer 1\n","  ▶ Training for Feature: voiced\n","Epoch 1/25 - Loss: 0.5691\n","Epoch 2/25 - Loss: 0.3214\n","Epoch 3/25 - Loss: 0.2093\n","Epoch 4/25 - Loss: 0.1707\n","Epoch 5/25 - Loss: 0.1519\n","Epoch 6/25 - Loss: 0.1376\n","Epoch 7/25 - Loss: 0.1285\n","Epoch 8/25 - Loss: 0.1211\n","Epoch 9/25 - Loss: 0.1155\n","Epoch 10/25 - Loss: 0.1109\n","Epoch 11/25 - Loss: 0.1070\n","Epoch 12/25 - Loss: 0.1030\n","Epoch 13/25 - Loss: 0.0998\n","Epoch 14/25 - Loss: 0.0967\n","Epoch 15/25 - Loss: 0.0928\n","Epoch 16/25 - Loss: 0.0899\n","Epoch 17/25 - Loss: 0.0875\n","Epoch 18/25 - Loss: 0.0847\n","Epoch 19/25 - Loss: 0.0818\n","Epoch 20/25 - Loss: 0.0792\n","Epoch 21/25 - Loss: 0.0768\n","Epoch 22/25 - Loss: 0.0744\n","Epoch 23/25 - Loss: 0.0722\n","Epoch 24/25 - Loss: 0.0694\n","Epoch 25/25 - Loss: 0.0671\n","📊 Evaluation Results - Acc: 0.860, Prec: 0.846, Rec: 0.902, F1: 0.874\n","     ➤ F1-score: 0.874, Accuracy: 0.860\n","  ▶ Training for Feature: fricative\n","Epoch 1/25 - Loss: 0.5308\n","Epoch 2/25 - Loss: 0.2919\n","Epoch 3/25 - Loss: 0.1952\n","Epoch 4/25 - Loss: 0.1569\n","Epoch 5/25 - Loss: 0.1350\n","Epoch 6/25 - Loss: 0.1205\n","Epoch 7/25 - Loss: 0.1099\n","Epoch 8/25 - Loss: 0.1024\n","Epoch 9/25 - Loss: 0.0951\n","Epoch 10/25 - Loss: 0.0888\n","Epoch 11/25 - Loss: 0.0833\n","Epoch 12/25 - Loss: 0.0790\n","Epoch 13/25 - Loss: 0.0749\n","Epoch 14/25 - Loss: 0.0714\n","Epoch 15/25 - Loss: 0.0678\n","Epoch 16/25 - Loss: 0.0645\n","Epoch 17/25 - Loss: 0.0616\n","Epoch 18/25 - Loss: 0.0588\n","Epoch 19/25 - Loss: 0.0563\n","Epoch 20/25 - Loss: 0.0534\n","Epoch 21/25 - Loss: 0.0512\n","Epoch 22/25 - Loss: 0.0491\n","Epoch 23/25 - Loss: 0.0475\n","Epoch 24/25 - Loss: 0.0445\n","Epoch 25/25 - Loss: 0.0428\n","📊 Evaluation Results - Acc: 0.903, Prec: 0.634, Rec: 0.703, F1: 0.667\n","     ➤ F1-score: 0.667, Accuracy: 0.903\n","  ▶ Training for Feature: nasal\n","Epoch 1/25 - Loss: 0.5330\n","Epoch 2/25 - Loss: 0.2775\n","Epoch 3/25 - Loss: 0.1604\n","Epoch 4/25 - Loss: 0.0946\n","Epoch 5/25 - Loss: 0.0697\n","Epoch 6/25 - Loss: 0.0557\n","Epoch 7/25 - Loss: 0.0477\n","Epoch 8/25 - Loss: 0.0434\n","Epoch 9/25 - Loss: 0.0405\n","Epoch 10/25 - Loss: 0.0379\n","Epoch 11/25 - Loss: 0.0358\n","Epoch 12/25 - Loss: 0.0338\n","Epoch 13/25 - Loss: 0.0320\n","Epoch 14/25 - Loss: 0.0304\n","Epoch 15/25 - Loss: 0.0291\n","Epoch 16/25 - Loss: 0.0277\n","Epoch 17/25 - Loss: 0.0263\n","Epoch 18/25 - Loss: 0.0255\n","Epoch 19/25 - Loss: 0.0241\n","Epoch 20/25 - Loss: 0.0233\n","Epoch 21/25 - Loss: 0.0224\n","Epoch 22/25 - Loss: 0.0213\n","Epoch 23/25 - Loss: 0.0202\n","Epoch 24/25 - Loss: 0.0197\n","Epoch 25/25 - Loss: 0.0190\n","📊 Evaluation Results - Acc: 0.968, Prec: 0.719, Rec: 0.742, F1: 0.730\n","     ➤ F1-score: 0.730, Accuracy: 0.968\n","\n","🔍 Processing Layer 2\n","  ▶ Training for Feature: voiced\n","Epoch 1/25 - Loss: 0.5545\n","Epoch 2/25 - Loss: 0.3196\n","Epoch 3/25 - Loss: 0.1991\n","Epoch 4/25 - Loss: 0.1528\n","Epoch 5/25 - Loss: 0.1307\n","Epoch 6/25 - Loss: 0.1172\n","Epoch 7/25 - Loss: 0.1082\n","Epoch 8/25 - Loss: 0.1018\n","Epoch 9/25 - Loss: 0.0969\n","Epoch 10/25 - Loss: 0.0923\n","Epoch 11/25 - Loss: 0.0885\n","Epoch 12/25 - Loss: 0.0853\n","Epoch 13/25 - Loss: 0.0819\n","Epoch 14/25 - Loss: 0.0800\n","Epoch 15/25 - Loss: 0.0762\n","Epoch 16/25 - Loss: 0.0733\n","Epoch 17/25 - Loss: 0.0710\n","Epoch 18/25 - Loss: 0.0695\n","Epoch 19/25 - Loss: 0.0668\n","Epoch 20/25 - Loss: 0.0642\n","Epoch 21/25 - Loss: 0.0618\n","Epoch 22/25 - Loss: 0.0608\n","Epoch 23/25 - Loss: 0.0588\n","Epoch 24/25 - Loss: 0.0568\n","Epoch 25/25 - Loss: 0.0543\n","📊 Evaluation Results - Acc: 0.871, Prec: 0.861, Rec: 0.906, F1: 0.883\n","     ➤ F1-score: 0.883, Accuracy: 0.871\n","  ▶ Training for Feature: fricative\n","Epoch 1/25 - Loss: 0.5825\n","Epoch 2/25 - Loss: 0.3530\n","Epoch 3/25 - Loss: 0.2437\n","Epoch 4/25 - Loss: 0.1774\n","Epoch 5/25 - Loss: 0.1427\n","Epoch 6/25 - Loss: 0.1177\n","Epoch 7/25 - Loss: 0.1016\n","Epoch 8/25 - Loss: 0.0902\n","Epoch 9/25 - Loss: 0.0815\n","Epoch 10/25 - Loss: 0.0743\n","Epoch 11/25 - Loss: 0.0689\n","Epoch 12/25 - Loss: 0.0640\n","Epoch 13/25 - Loss: 0.0597\n","Epoch 14/25 - Loss: 0.0566\n","Epoch 15/25 - Loss: 0.0531\n","Epoch 16/25 - Loss: 0.0501\n","Epoch 17/25 - Loss: 0.0476\n","Epoch 18/25 - Loss: 0.0452\n","Epoch 19/25 - Loss: 0.0428\n","Epoch 20/25 - Loss: 0.0407\n","Epoch 21/25 - Loss: 0.0387\n","Epoch 22/25 - Loss: 0.0370\n","Epoch 23/25 - Loss: 0.0352\n","Epoch 24/25 - Loss: 0.0339\n","Epoch 25/25 - Loss: 0.0325\n","📊 Evaluation Results - Acc: 0.925, Prec: 0.713, Rec: 0.770, F1: 0.740\n","     ➤ F1-score: 0.740, Accuracy: 0.925\n","  ▶ Training for Feature: nasal\n","Epoch 1/25 - Loss: 0.5366\n","Epoch 2/25 - Loss: 0.2772\n","Epoch 3/25 - Loss: 0.1726\n","Epoch 4/25 - Loss: 0.1041\n","Epoch 5/25 - Loss: 0.0720\n","Epoch 6/25 - Loss: 0.0558\n","Epoch 7/25 - Loss: 0.0469\n","Epoch 8/25 - Loss: 0.0415\n","Epoch 9/25 - Loss: 0.0381\n","Epoch 10/25 - Loss: 0.0354\n","Epoch 11/25 - Loss: 0.0334\n","Epoch 12/25 - Loss: 0.0310\n","Epoch 13/25 - Loss: 0.0289\n","Epoch 14/25 - Loss: 0.0271\n","Epoch 15/25 - Loss: 0.0258\n","Epoch 16/25 - Loss: 0.0242\n","Epoch 17/25 - Loss: 0.0229\n","Epoch 18/25 - Loss: 0.0217\n","Epoch 19/25 - Loss: 0.0205\n","Epoch 20/25 - Loss: 0.0193\n","Epoch 21/25 - Loss: 0.0183\n","Epoch 22/25 - Loss: 0.0175\n","Epoch 23/25 - Loss: 0.0169\n","Epoch 24/25 - Loss: 0.0157\n","Epoch 25/25 - Loss: 0.0151\n","📊 Evaluation Results - Acc: 0.968, Prec: 0.719, Rec: 0.742, F1: 0.730\n","     ➤ F1-score: 0.730, Accuracy: 0.968\n","\n","🔍 Processing Layer 3\n","  ▶ Training for Feature: voiced\n","Epoch 1/25 - Loss: 0.5857\n","Epoch 2/25 - Loss: 0.3472\n","Epoch 3/25 - Loss: 0.2105\n","Epoch 4/25 - Loss: 0.1525\n","Epoch 5/25 - Loss: 0.1265\n","Epoch 6/25 - Loss: 0.1115\n","Epoch 7/25 - Loss: 0.1021\n","Epoch 8/25 - Loss: 0.0947\n","Epoch 9/25 - Loss: 0.0885\n","Epoch 10/25 - Loss: 0.0844\n","Epoch 11/25 - Loss: 0.0787\n","Epoch 12/25 - Loss: 0.0748\n","Epoch 13/25 - Loss: 0.0709\n","Epoch 14/25 - Loss: 0.0675\n","Epoch 15/25 - Loss: 0.0645\n","Epoch 16/25 - Loss: 0.0612\n","Epoch 17/25 - Loss: 0.0585\n","Epoch 18/25 - Loss: 0.0559\n","Epoch 19/25 - Loss: 0.0529\n","Epoch 20/25 - Loss: 0.0505\n","Epoch 21/25 - Loss: 0.0482\n","Epoch 22/25 - Loss: 0.0466\n","Epoch 23/25 - Loss: 0.0443\n","Epoch 24/25 - Loss: 0.0419\n","Epoch 25/25 - Loss: 0.0402\n","📊 Evaluation Results - Acc: 0.869, Prec: 0.853, Rec: 0.913, F1: 0.882\n","     ➤ F1-score: 0.882, Accuracy: 0.869\n","  ▶ Training for Feature: fricative\n","Epoch 1/25 - Loss: 0.5259\n","Epoch 2/25 - Loss: 0.2883\n","Epoch 3/25 - Loss: 0.1811\n","Epoch 4/25 - Loss: 0.1265\n","Epoch 5/25 - Loss: 0.0957\n","Epoch 6/25 - Loss: 0.0771\n","Epoch 7/25 - Loss: 0.0664\n","Epoch 8/25 - Loss: 0.0592\n","Epoch 9/25 - Loss: 0.0529\n","Epoch 10/25 - Loss: 0.0481\n","Epoch 11/25 - Loss: 0.0438\n","Epoch 12/25 - Loss: 0.0404\n","Epoch 13/25 - Loss: 0.0376\n","Epoch 14/25 - Loss: 0.0346\n","Epoch 15/25 - Loss: 0.0329\n","Epoch 16/25 - Loss: 0.0305\n","Epoch 17/25 - Loss: 0.0283\n","Epoch 18/25 - Loss: 0.0265\n","Epoch 19/25 - Loss: 0.0248\n","Epoch 20/25 - Loss: 0.0231\n","Epoch 21/25 - Loss: 0.0216\n","Epoch 22/25 - Loss: 0.0200\n","Epoch 23/25 - Loss: 0.0187\n","Epoch 24/25 - Loss: 0.0175\n","Epoch 25/25 - Loss: 0.0162\n","📊 Evaluation Results - Acc: 0.929, Prec: 0.714, Rec: 0.811, F1: 0.759\n","     ➤ F1-score: 0.759, Accuracy: 0.929\n","  ▶ Training for Feature: nasal\n","Epoch 1/25 - Loss: 0.5216\n","Epoch 2/25 - Loss: 0.2600\n","Epoch 3/25 - Loss: 0.1312\n","Epoch 4/25 - Loss: 0.0731\n","Epoch 5/25 - Loss: 0.0495\n","Epoch 6/25 - Loss: 0.0390\n","Epoch 7/25 - Loss: 0.0344\n","Epoch 8/25 - Loss: 0.0310\n","Epoch 9/25 - Loss: 0.0281\n","Epoch 10/25 - Loss: 0.0254\n","Epoch 11/25 - Loss: 0.0235\n","Epoch 12/25 - Loss: 0.0217\n","Epoch 13/25 - Loss: 0.0203\n","Epoch 14/25 - Loss: 0.0189\n","Epoch 15/25 - Loss: 0.0175\n","Epoch 16/25 - Loss: 0.0163\n","Epoch 17/25 - Loss: 0.0151\n","Epoch 18/25 - Loss: 0.0140\n","Epoch 19/25 - Loss: 0.0130\n","Epoch 20/25 - Loss: 0.0121\n","Epoch 21/25 - Loss: 0.0114\n","Epoch 22/25 - Loss: 0.0105\n","Epoch 23/25 - Loss: 0.0099\n","Epoch 24/25 - Loss: 0.0091\n","Epoch 25/25 - Loss: 0.0085\n","📊 Evaluation Results - Acc: 0.970, Prec: 0.742, Rec: 0.742, F1: 0.742\n","     ➤ F1-score: 0.742, Accuracy: 0.970\n","\n","🔍 Processing Layer 4\n","  ▶ Training for Feature: voiced\n","Epoch 1/25 - Loss: 0.5710\n","Epoch 2/25 - Loss: 0.3391\n","Epoch 3/25 - Loss: 0.1996\n","Epoch 4/25 - Loss: 0.1438\n","Epoch 5/25 - Loss: 0.1167\n","Epoch 6/25 - Loss: 0.1019\n","Epoch 7/25 - Loss: 0.0919\n","Epoch 8/25 - Loss: 0.0847\n","Epoch 9/25 - Loss: 0.0789\n","Epoch 10/25 - Loss: 0.0736\n","Epoch 11/25 - Loss: 0.0689\n","Epoch 12/25 - Loss: 0.0645\n","Epoch 13/25 - Loss: 0.0610\n","Epoch 14/25 - Loss: 0.0584\n","Epoch 15/25 - Loss: 0.0549\n","Epoch 16/25 - Loss: 0.0517\n","Epoch 17/25 - Loss: 0.0491\n","Epoch 18/25 - Loss: 0.0464\n","Epoch 19/25 - Loss: 0.0443\n","Epoch 20/25 - Loss: 0.0417\n","Epoch 21/25 - Loss: 0.0397\n","Epoch 22/25 - Loss: 0.0371\n","Epoch 23/25 - Loss: 0.0354\n","Epoch 24/25 - Loss: 0.0339\n","Epoch 25/25 - Loss: 0.0320\n","📊 Evaluation Results - Acc: 0.881, Prec: 0.866, Rec: 0.920, F1: 0.892\n","     ➤ F1-score: 0.892, Accuracy: 0.881\n","  ▶ Training for Feature: fricative\n","Epoch 1/25 - Loss: 0.5723\n","Epoch 2/25 - Loss: 0.3367\n","Epoch 3/25 - Loss: 0.1938\n","Epoch 4/25 - Loss: 0.1208\n","Epoch 5/25 - Loss: 0.0863\n","Epoch 6/25 - Loss: 0.0683\n","Epoch 7/25 - Loss: 0.0581\n","Epoch 8/25 - Loss: 0.0511\n","Epoch 9/25 - Loss: 0.0458\n","Epoch 10/25 - Loss: 0.0421\n","Epoch 11/25 - Loss: 0.0385\n","Epoch 12/25 - Loss: 0.0354\n","Epoch 13/25 - Loss: 0.0326\n","Epoch 14/25 - Loss: 0.0301\n","Epoch 15/25 - Loss: 0.0279\n","Epoch 16/25 - Loss: 0.0261\n","Epoch 17/25 - Loss: 0.0239\n","Epoch 18/25 - Loss: 0.0222\n","Epoch 19/25 - Loss: 0.0204\n","Epoch 20/25 - Loss: 0.0189\n","Epoch 21/25 - Loss: 0.0174\n","Epoch 22/25 - Loss: 0.0163\n","Epoch 23/25 - Loss: 0.0147\n","Epoch 24/25 - Loss: 0.0137\n","Epoch 25/25 - Loss: 0.0126\n","📊 Evaluation Results - Acc: 0.925, Prec: 0.718, Rec: 0.757, F1: 0.737\n","     ➤ F1-score: 0.737, Accuracy: 0.925\n","  ▶ Training for Feature: nasal\n","Epoch 1/25 - Loss: 0.5444\n","Epoch 2/25 - Loss: 0.2803\n","Epoch 3/25 - Loss: 0.1327\n","Epoch 4/25 - Loss: 0.0688\n","Epoch 5/25 - Loss: 0.0455\n","Epoch 6/25 - Loss: 0.0372\n","Epoch 7/25 - Loss: 0.0327\n","Epoch 8/25 - Loss: 0.0293\n","Epoch 9/25 - Loss: 0.0270\n","Epoch 10/25 - Loss: 0.0245\n","Epoch 11/25 - Loss: 0.0230\n","Epoch 12/25 - Loss: 0.0213\n","Epoch 13/25 - Loss: 0.0199\n","Epoch 14/25 - Loss: 0.0188\n","Epoch 15/25 - Loss: 0.0175\n","Epoch 16/25 - Loss: 0.0165\n","Epoch 17/25 - Loss: 0.0154\n","Epoch 18/25 - Loss: 0.0146\n","Epoch 19/25 - Loss: 0.0136\n","Epoch 20/25 - Loss: 0.0127\n","Epoch 21/25 - Loss: 0.0120\n","Epoch 22/25 - Loss: 0.0111\n","Epoch 23/25 - Loss: 0.0105\n","Epoch 24/25 - Loss: 0.0099\n","Epoch 25/25 - Loss: 0.0091\n","📊 Evaluation Results - Acc: 0.966, Prec: 0.710, Rec: 0.710, F1: 0.710\n","     ➤ F1-score: 0.710, Accuracy: 0.966\n","\n","🔍 Processing Layer 5\n","  ▶ Training for Feature: voiced\n","Epoch 1/25 - Loss: 0.5824\n","Epoch 2/25 - Loss: 0.3547\n","Epoch 3/25 - Loss: 0.2039\n","Epoch 4/25 - Loss: 0.1344\n","Epoch 5/25 - Loss: 0.1008\n","Epoch 6/25 - Loss: 0.0849\n","Epoch 7/25 - Loss: 0.0746\n","Epoch 8/25 - Loss: 0.0676\n","Epoch 9/25 - Loss: 0.0623\n","Epoch 10/25 - Loss: 0.0576\n","Epoch 11/25 - Loss: 0.0535\n","Epoch 12/25 - Loss: 0.0499\n","Epoch 13/25 - Loss: 0.0483\n","Epoch 14/25 - Loss: 0.0456\n","Epoch 15/25 - Loss: 0.0420\n","Epoch 16/25 - Loss: 0.0402\n","Epoch 17/25 - Loss: 0.0372\n","Epoch 18/25 - Loss: 0.0353\n","Epoch 19/25 - Loss: 0.0334\n","Epoch 20/25 - Loss: 0.0319\n","Epoch 21/25 - Loss: 0.0300\n","Epoch 22/25 - Loss: 0.0288\n","Epoch 23/25 - Loss: 0.0269\n","Epoch 24/25 - Loss: 0.0256\n","Epoch 25/25 - Loss: 0.0238\n","📊 Evaluation Results - Acc: 0.882, Prec: 0.871, Rec: 0.916, F1: 0.893\n","     ➤ F1-score: 0.893, Accuracy: 0.882\n","  ▶ Training for Feature: fricative\n","Epoch 1/25 - Loss: 0.5383\n","Epoch 2/25 - Loss: 0.3049\n","Epoch 3/25 - Loss: 0.1721\n","Epoch 4/25 - Loss: 0.1016\n","Epoch 5/25 - Loss: 0.0699\n","Epoch 6/25 - Loss: 0.0531\n","Epoch 7/25 - Loss: 0.0434\n","Epoch 8/25 - Loss: 0.0374\n","Epoch 9/25 - Loss: 0.0330\n","Epoch 10/25 - Loss: 0.0296\n","Epoch 11/25 - Loss: 0.0266\n","Epoch 12/25 - Loss: 0.0243\n","Epoch 13/25 - Loss: 0.0220\n","Epoch 14/25 - Loss: 0.0202\n","Epoch 15/25 - Loss: 0.0182\n","Epoch 16/25 - Loss: 0.0170\n","Epoch 17/25 - Loss: 0.0155\n","Epoch 18/25 - Loss: 0.0142\n","Epoch 19/25 - Loss: 0.0130\n","Epoch 20/25 - Loss: 0.0120\n","Epoch 21/25 - Loss: 0.0110\n","Epoch 22/25 - Loss: 0.0100\n","Epoch 23/25 - Loss: 0.0094\n","Epoch 24/25 - Loss: 0.0085\n","Epoch 25/25 - Loss: 0.0080\n","📊 Evaluation Results - Acc: 0.948, Prec: 0.787, Rec: 0.851, F1: 0.818\n","     ➤ F1-score: 0.818, Accuracy: 0.948\n","  ▶ Training for Feature: nasal\n","Epoch 1/25 - Loss: 0.5484\n","Epoch 2/25 - Loss: 0.3023\n","Epoch 3/25 - Loss: 0.1602\n","Epoch 4/25 - Loss: 0.0824\n","Epoch 5/25 - Loss: 0.0501\n","Epoch 6/25 - Loss: 0.0381\n","Epoch 7/25 - Loss: 0.0308\n","Epoch 8/25 - Loss: 0.0270\n","Epoch 9/25 - Loss: 0.0241\n","Epoch 10/25 - Loss: 0.0220\n","Epoch 11/25 - Loss: 0.0200\n","Epoch 12/25 - Loss: 0.0183\n","Epoch 13/25 - Loss: 0.0167\n","Epoch 14/25 - Loss: 0.0157\n","Epoch 15/25 - Loss: 0.0142\n","Epoch 16/25 - Loss: 0.0129\n","Epoch 17/25 - Loss: 0.0119\n","Epoch 18/25 - Loss: 0.0110\n","Epoch 19/25 - Loss: 0.0101\n","Epoch 20/25 - Loss: 0.0091\n","Epoch 21/25 - Loss: 0.0084\n","Epoch 22/25 - Loss: 0.0078\n","Epoch 23/25 - Loss: 0.0072\n","Epoch 24/25 - Loss: 0.0066\n","Epoch 25/25 - Loss: 0.0061\n","📊 Evaluation Results - Acc: 0.968, Prec: 0.750, Rec: 0.677, F1: 0.712\n","     ➤ F1-score: 0.712, Accuracy: 0.968\n","\n","🔍 Processing Layer 6\n","  ▶ Training for Feature: voiced\n","Epoch 1/25 - Loss: 0.5953\n","Epoch 2/25 - Loss: 0.3668\n","Epoch 3/25 - Loss: 0.2094\n","Epoch 4/25 - Loss: 0.1318\n","Epoch 5/25 - Loss: 0.0956\n","Epoch 6/25 - Loss: 0.0776\n","Epoch 7/25 - Loss: 0.0677\n","Epoch 8/25 - Loss: 0.0609\n","Epoch 9/25 - Loss: 0.0554\n","Epoch 10/25 - Loss: 0.0513\n","Epoch 11/25 - Loss: 0.0476\n","Epoch 12/25 - Loss: 0.0443\n","Epoch 13/25 - Loss: 0.0413\n","Epoch 14/25 - Loss: 0.0382\n","Epoch 15/25 - Loss: 0.0361\n","Epoch 16/25 - Loss: 0.0335\n","Epoch 17/25 - Loss: 0.0314\n","Epoch 18/25 - Loss: 0.0297\n","Epoch 19/25 - Loss: 0.0276\n","Epoch 20/25 - Loss: 0.0257\n","Epoch 21/25 - Loss: 0.0240\n","Epoch 22/25 - Loss: 0.0225\n","Epoch 23/25 - Loss: 0.0211\n","Epoch 24/25 - Loss: 0.0198\n","Epoch 25/25 - Loss: 0.0185\n","📊 Evaluation Results - Acc: 0.910, Prec: 0.897, Rec: 0.941, F1: 0.918\n","     ➤ F1-score: 0.918, Accuracy: 0.910\n","  ▶ Training for Feature: fricative\n","Epoch 1/25 - Loss: 0.5333\n","Epoch 2/25 - Loss: 0.3019\n","Epoch 3/25 - Loss: 0.1698\n","Epoch 4/25 - Loss: 0.1012\n","Epoch 5/25 - Loss: 0.0673\n","Epoch 6/25 - Loss: 0.0504\n","Epoch 7/25 - Loss: 0.0421\n","Epoch 8/25 - Loss: 0.0361\n","Epoch 9/25 - Loss: 0.0319\n","Epoch 10/25 - Loss: 0.0286\n","Epoch 11/25 - Loss: 0.0260\n","Epoch 12/25 - Loss: 0.0237\n","Epoch 13/25 - Loss: 0.0217\n","Epoch 14/25 - Loss: 0.0200\n","Epoch 15/25 - Loss: 0.0184\n","Epoch 16/25 - Loss: 0.0168\n","Epoch 17/25 - Loss: 0.0158\n","Epoch 18/25 - Loss: 0.0144\n","Epoch 19/25 - Loss: 0.0134\n","Epoch 20/25 - Loss: 0.0123\n","Epoch 21/25 - Loss: 0.0114\n","Epoch 22/25 - Loss: 0.0105\n","Epoch 23/25 - Loss: 0.0098\n","Epoch 24/25 - Loss: 0.0091\n","Epoch 25/25 - Loss: 0.0084\n","📊 Evaluation Results - Acc: 0.946, Prec: 0.792, Rec: 0.824, F1: 0.808\n","     ➤ F1-score: 0.808, Accuracy: 0.946\n","  ▶ Training for Feature: nasal\n","Epoch 1/25 - Loss: 0.5376\n","Epoch 2/25 - Loss: 0.2807\n","Epoch 3/25 - Loss: 0.1517\n","Epoch 4/25 - Loss: 0.0802\n","Epoch 5/25 - Loss: 0.0508\n","Epoch 6/25 - Loss: 0.0376\n","Epoch 7/25 - Loss: 0.0300\n","Epoch 8/25 - Loss: 0.0257\n","Epoch 9/25 - Loss: 0.0224\n","Epoch 10/25 - Loss: 0.0199\n","Epoch 11/25 - Loss: 0.0184\n","Epoch 12/25 - Loss: 0.0165\n","Epoch 13/25 - Loss: 0.0150\n","Epoch 14/25 - Loss: 0.0139\n","Epoch 15/25 - Loss: 0.0128\n","Epoch 16/25 - Loss: 0.0116\n","Epoch 17/25 - Loss: 0.0107\n","Epoch 18/25 - Loss: 0.0098\n","Epoch 19/25 - Loss: 0.0089\n","Epoch 20/25 - Loss: 0.0082\n","Epoch 21/25 - Loss: 0.0075\n","Epoch 22/25 - Loss: 0.0069\n","Epoch 23/25 - Loss: 0.0063\n","Epoch 24/25 - Loss: 0.0057\n","Epoch 25/25 - Loss: 0.0053\n","📊 Evaluation Results - Acc: 0.972, Prec: 0.786, Rec: 0.710, F1: 0.746\n","     ➤ F1-score: 0.746, Accuracy: 0.972\n","\n","🔍 Processing Layer 7\n","  ▶ Training for Feature: voiced\n","Epoch 1/25 - Loss: 0.5855\n","Epoch 2/25 - Loss: 0.3594\n","Epoch 3/25 - Loss: 0.2057\n","Epoch 4/25 - Loss: 0.1276\n","Epoch 5/25 - Loss: 0.0923\n","Epoch 6/25 - Loss: 0.0745\n","Epoch 7/25 - Loss: 0.0653\n","Epoch 8/25 - Loss: 0.0578\n","Epoch 9/25 - Loss: 0.0526\n","Epoch 10/25 - Loss: 0.0485\n","Epoch 11/25 - Loss: 0.0451\n","Epoch 12/25 - Loss: 0.0420\n","Epoch 13/25 - Loss: 0.0394\n","Epoch 14/25 - Loss: 0.0369\n","Epoch 15/25 - Loss: 0.0342\n","Epoch 16/25 - Loss: 0.0320\n","Epoch 17/25 - Loss: 0.0304\n","Epoch 18/25 - Loss: 0.0285\n","Epoch 19/25 - Loss: 0.0265\n","Epoch 20/25 - Loss: 0.0249\n","Epoch 21/25 - Loss: 0.0233\n","Epoch 22/25 - Loss: 0.0220\n","Epoch 23/25 - Loss: 0.0206\n","Epoch 24/25 - Loss: 0.0196\n","Epoch 25/25 - Loss: 0.0184\n","📊 Evaluation Results - Acc: 0.897, Prec: 0.882, Rec: 0.934, F1: 0.907\n","     ➤ F1-score: 0.907, Accuracy: 0.897\n","  ▶ Training for Feature: fricative\n","Epoch 1/25 - Loss: 0.5756\n","Epoch 2/25 - Loss: 0.3463\n","Epoch 3/25 - Loss: 0.2019\n","Epoch 4/25 - Loss: 0.1171\n","Epoch 5/25 - Loss: 0.0760\n","Epoch 6/25 - Loss: 0.0555\n","Epoch 7/25 - Loss: 0.0442\n","Epoch 8/25 - Loss: 0.0379\n","Epoch 9/25 - Loss: 0.0330\n","Epoch 10/25 - Loss: 0.0296\n","Epoch 11/25 - Loss: 0.0264\n","Epoch 12/25 - Loss: 0.0240\n","Epoch 13/25 - Loss: 0.0218\n","Epoch 14/25 - Loss: 0.0198\n","Epoch 15/25 - Loss: 0.0179\n","Epoch 16/25 - Loss: 0.0163\n","Epoch 17/25 - Loss: 0.0146\n","Epoch 18/25 - Loss: 0.0133\n","Epoch 19/25 - Loss: 0.0121\n","Epoch 20/25 - Loss: 0.0109\n","Epoch 21/25 - Loss: 0.0099\n","Epoch 22/25 - Loss: 0.0090\n","Epoch 23/25 - Loss: 0.0082\n","Epoch 24/25 - Loss: 0.0076\n","Epoch 25/25 - Loss: 0.0070\n","📊 Evaluation Results - Acc: 0.948, Prec: 0.787, Rec: 0.851, F1: 0.818\n","     ➤ F1-score: 0.818, Accuracy: 0.948\n","  ▶ Training for Feature: nasal\n","Epoch 1/25 - Loss: 0.5248\n","Epoch 2/25 - Loss: 0.2911\n","Epoch 3/25 - Loss: 0.1603\n","Epoch 4/25 - Loss: 0.0873\n","Epoch 5/25 - Loss: 0.0532\n","Epoch 6/25 - Loss: 0.0382\n","Epoch 7/25 - Loss: 0.0299\n","Epoch 8/25 - Loss: 0.0245\n","Epoch 9/25 - Loss: 0.0212\n","Epoch 10/25 - Loss: 0.0188\n","Epoch 11/25 - Loss: 0.0167\n","Epoch 12/25 - Loss: 0.0150\n","Epoch 13/25 - Loss: 0.0137\n","Epoch 14/25 - Loss: 0.0124\n","Epoch 15/25 - Loss: 0.0112\n","Epoch 16/25 - Loss: 0.0101\n","Epoch 17/25 - Loss: 0.0092\n","Epoch 18/25 - Loss: 0.0084\n","Epoch 19/25 - Loss: 0.0077\n","Epoch 20/25 - Loss: 0.0069\n","Epoch 21/25 - Loss: 0.0063\n","Epoch 22/25 - Loss: 0.0057\n","Epoch 23/25 - Loss: 0.0052\n","Epoch 24/25 - Loss: 0.0048\n","Epoch 25/25 - Loss: 0.0044\n","📊 Evaluation Results - Acc: 0.968, Prec: 0.750, Rec: 0.677, F1: 0.712\n","     ➤ F1-score: 0.712, Accuracy: 0.968\n","\n","🔍 Processing Layer 8\n","  ▶ Training for Feature: voiced\n","Epoch 1/25 - Loss: 0.5970\n","Epoch 2/25 - Loss: 0.3787\n","Epoch 3/25 - Loss: 0.2208\n","Epoch 4/25 - Loss: 0.1371\n","Epoch 5/25 - Loss: 0.0949\n","Epoch 6/25 - Loss: 0.0750\n","Epoch 7/25 - Loss: 0.0630\n","Epoch 8/25 - Loss: 0.0554\n","Epoch 9/25 - Loss: 0.0500\n","Epoch 10/25 - Loss: 0.0453\n","Epoch 11/25 - Loss: 0.0413\n","Epoch 12/25 - Loss: 0.0384\n","Epoch 13/25 - Loss: 0.0358\n","Epoch 14/25 - Loss: 0.0334\n","Epoch 15/25 - Loss: 0.0310\n","Epoch 16/25 - Loss: 0.0298\n","Epoch 17/25 - Loss: 0.0275\n","Epoch 18/25 - Loss: 0.0257\n","Epoch 19/25 - Loss: 0.0242\n","Epoch 20/25 - Loss: 0.0229\n","Epoch 21/25 - Loss: 0.0220\n","Epoch 22/25 - Loss: 0.0203\n","Epoch 23/25 - Loss: 0.0192\n","Epoch 24/25 - Loss: 0.0183\n","Epoch 25/25 - Loss: 0.0172\n","📊 Evaluation Results - Acc: 0.914, Prec: 0.908, Rec: 0.934, F1: 0.921\n","     ➤ F1-score: 0.921, Accuracy: 0.914\n","  ▶ Training for Feature: fricative\n","Epoch 1/25 - Loss: 0.5916\n","Epoch 2/25 - Loss: 0.3665\n","Epoch 3/25 - Loss: 0.2190\n","Epoch 4/25 - Loss: 0.1330\n","Epoch 5/25 - Loss: 0.0870\n","Epoch 6/25 - Loss: 0.0614\n","Epoch 7/25 - Loss: 0.0480\n","Epoch 8/25 - Loss: 0.0409\n","Epoch 9/25 - Loss: 0.0361\n","Epoch 10/25 - Loss: 0.0324\n","Epoch 11/25 - Loss: 0.0293\n","Epoch 12/25 - Loss: 0.0270\n","Epoch 13/25 - Loss: 0.0247\n","Epoch 14/25 - Loss: 0.0231\n","Epoch 15/25 - Loss: 0.0213\n","Epoch 16/25 - Loss: 0.0196\n","Epoch 17/25 - Loss: 0.0181\n","Epoch 18/25 - Loss: 0.0170\n","Epoch 19/25 - Loss: 0.0155\n","Epoch 20/25 - Loss: 0.0144\n","Epoch 21/25 - Loss: 0.0132\n","Epoch 22/25 - Loss: 0.0123\n","Epoch 23/25 - Loss: 0.0114\n","Epoch 24/25 - Loss: 0.0105\n","Epoch 25/25 - Loss: 0.0098\n","📊 Evaluation Results - Acc: 0.955, Prec: 0.838, Rec: 0.838, F1: 0.838\n","     ➤ F1-score: 0.838, Accuracy: 0.955\n","  ▶ Training for Feature: nasal\n","Epoch 1/25 - Loss: 0.5542\n","Epoch 2/25 - Loss: 0.3114\n","Epoch 3/25 - Loss: 0.1870\n","Epoch 4/25 - Loss: 0.1067\n","Epoch 5/25 - Loss: 0.0651\n","Epoch 6/25 - Loss: 0.0453\n","Epoch 7/25 - Loss: 0.0343\n","Epoch 8/25 - Loss: 0.0281\n","Epoch 9/25 - Loss: 0.0236\n","Epoch 10/25 - Loss: 0.0209\n","Epoch 11/25 - Loss: 0.0185\n","Epoch 12/25 - Loss: 0.0167\n","Epoch 13/25 - Loss: 0.0150\n","Epoch 14/25 - Loss: 0.0135\n","Epoch 15/25 - Loss: 0.0123\n","Epoch 16/25 - Loss: 0.0111\n","Epoch 17/25 - Loss: 0.0099\n","Epoch 18/25 - Loss: 0.0090\n","Epoch 19/25 - Loss: 0.0082\n","Epoch 20/25 - Loss: 0.0075\n","Epoch 21/25 - Loss: 0.0067\n","Epoch 22/25 - Loss: 0.0061\n","Epoch 23/25 - Loss: 0.0055\n","Epoch 24/25 - Loss: 0.0051\n","Epoch 25/25 - Loss: 0.0046\n","📊 Evaluation Results - Acc: 0.970, Prec: 0.778, Rec: 0.677, F1: 0.724\n","     ➤ F1-score: 0.724, Accuracy: 0.970\n","\n","🔍 Processing Layer 9\n","  ▶ Training for Feature: voiced\n","Epoch 1/25 - Loss: 0.5938\n","Epoch 2/25 - Loss: 0.3825\n","Epoch 3/25 - Loss: 0.2347\n","Epoch 4/25 - Loss: 0.1517\n","Epoch 5/25 - Loss: 0.1063\n","Epoch 6/25 - Loss: 0.0826\n","Epoch 7/25 - Loss: 0.0692\n","Epoch 8/25 - Loss: 0.0607\n","Epoch 9/25 - Loss: 0.0543\n","Epoch 10/25 - Loss: 0.0487\n","Epoch 11/25 - Loss: 0.0451\n","Epoch 12/25 - Loss: 0.0412\n","Epoch 13/25 - Loss: 0.0383\n","Epoch 14/25 - Loss: 0.0359\n","Epoch 15/25 - Loss: 0.0334\n","Epoch 16/25 - Loss: 0.0310\n","Epoch 17/25 - Loss: 0.0293\n","Epoch 18/25 - Loss: 0.0275\n","Epoch 19/25 - Loss: 0.0256\n","Epoch 20/25 - Loss: 0.0242\n","Epoch 21/25 - Loss: 0.0227\n","Epoch 22/25 - Loss: 0.0215\n","Epoch 23/25 - Loss: 0.0200\n","Epoch 24/25 - Loss: 0.0192\n","Epoch 25/25 - Loss: 0.0180\n","📊 Evaluation Results - Acc: 0.886, Prec: 0.879, Rec: 0.913, F1: 0.896\n","     ➤ F1-score: 0.896, Accuracy: 0.886\n","  ▶ Training for Feature: fricative\n","Epoch 1/25 - Loss: 0.5917\n","Epoch 2/25 - Loss: 0.3667\n","Epoch 3/25 - Loss: 0.2268\n","Epoch 4/25 - Loss: 0.1449\n","Epoch 5/25 - Loss: 0.0990\n","Epoch 6/25 - Loss: 0.0713\n","Epoch 7/25 - Loss: 0.0554\n","Epoch 8/25 - Loss: 0.0460\n","Epoch 9/25 - Loss: 0.0398\n","Epoch 10/25 - Loss: 0.0353\n","Epoch 11/25 - Loss: 0.0319\n","Epoch 12/25 - Loss: 0.0286\n","Epoch 13/25 - Loss: 0.0263\n","Epoch 14/25 - Loss: 0.0243\n","Epoch 15/25 - Loss: 0.0222\n","Epoch 16/25 - Loss: 0.0205\n","Epoch 17/25 - Loss: 0.0188\n","Epoch 18/25 - Loss: 0.0174\n","Epoch 19/25 - Loss: 0.0163\n","Epoch 20/25 - Loss: 0.0153\n","Epoch 21/25 - Loss: 0.0139\n","Epoch 22/25 - Loss: 0.0129\n","Epoch 23/25 - Loss: 0.0122\n","Epoch 24/25 - Loss: 0.0113\n","Epoch 25/25 - Loss: 0.0106\n","📊 Evaluation Results - Acc: 0.948, Prec: 0.819, Rec: 0.797, F1: 0.808\n","     ➤ F1-score: 0.808, Accuracy: 0.948\n","  ▶ Training for Feature: nasal\n","Epoch 1/25 - Loss: 0.5680\n","Epoch 2/25 - Loss: 0.3318\n","Epoch 3/25 - Loss: 0.2002\n","Epoch 4/25 - Loss: 0.1175\n","Epoch 5/25 - Loss: 0.0726\n","Epoch 6/25 - Loss: 0.0495\n","Epoch 7/25 - Loss: 0.0366\n","Epoch 8/25 - Loss: 0.0295\n","Epoch 9/25 - Loss: 0.0245\n","Epoch 10/25 - Loss: 0.0209\n","Epoch 11/25 - Loss: 0.0184\n","Epoch 12/25 - Loss: 0.0163\n","Epoch 13/25 - Loss: 0.0145\n","Epoch 14/25 - Loss: 0.0131\n","Epoch 15/25 - Loss: 0.0117\n","Epoch 16/25 - Loss: 0.0106\n","Epoch 17/25 - Loss: 0.0096\n","Epoch 18/25 - Loss: 0.0088\n","Epoch 19/25 - Loss: 0.0079\n","Epoch 20/25 - Loss: 0.0073\n","Epoch 21/25 - Loss: 0.0066\n","Epoch 22/25 - Loss: 0.0061\n","Epoch 23/25 - Loss: 0.0055\n","Epoch 24/25 - Loss: 0.0052\n","Epoch 25/25 - Loss: 0.0048\n","📊 Evaluation Results - Acc: 0.974, Prec: 0.815, Rec: 0.710, F1: 0.759\n","     ➤ F1-score: 0.759, Accuracy: 0.974\n","\n","🔍 Processing Layer 10\n","  ▶ Training for Feature: voiced\n","Epoch 1/25 - Loss: 0.5816\n","Epoch 2/25 - Loss: 0.3536\n","Epoch 3/25 - Loss: 0.2049\n","Epoch 4/25 - Loss: 0.1313\n","Epoch 5/25 - Loss: 0.0943\n","Epoch 6/25 - Loss: 0.0762\n","Epoch 7/25 - Loss: 0.0644\n","Epoch 8/25 - Loss: 0.0570\n","Epoch 9/25 - Loss: 0.0510\n","Epoch 10/25 - Loss: 0.0471\n","Epoch 11/25 - Loss: 0.0431\n","Epoch 12/25 - Loss: 0.0405\n","Epoch 13/25 - Loss: 0.0379\n","Epoch 14/25 - Loss: 0.0355\n","Epoch 15/25 - Loss: 0.0338\n","Epoch 16/25 - Loss: 0.0314\n","Epoch 17/25 - Loss: 0.0297\n","Epoch 18/25 - Loss: 0.0280\n","Epoch 19/25 - Loss: 0.0264\n","Epoch 20/25 - Loss: 0.0249\n","Epoch 21/25 - Loss: 0.0235\n","Epoch 22/25 - Loss: 0.0226\n","Epoch 23/25 - Loss: 0.0214\n","Epoch 24/25 - Loss: 0.0204\n","Epoch 25/25 - Loss: 0.0196\n","📊 Evaluation Results - Acc: 0.897, Prec: 0.897, Rec: 0.913, F1: 0.905\n","     ➤ F1-score: 0.905, Accuracy: 0.897\n","  ▶ Training for Feature: fricative\n","Epoch 1/25 - Loss: 0.5815\n","Epoch 2/25 - Loss: 0.3554\n","Epoch 3/25 - Loss: 0.2130\n","Epoch 4/25 - Loss: 0.1312\n","Epoch 5/25 - Loss: 0.0853\n","Epoch 6/25 - Loss: 0.0598\n","Epoch 7/25 - Loss: 0.0458\n","Epoch 8/25 - Loss: 0.0381\n","Epoch 9/25 - Loss: 0.0330\n","Epoch 10/25 - Loss: 0.0294\n","Epoch 11/25 - Loss: 0.0265\n","Epoch 12/25 - Loss: 0.0242\n","Epoch 13/25 - Loss: 0.0223\n","Epoch 14/25 - Loss: 0.0204\n","Epoch 15/25 - Loss: 0.0188\n","Epoch 16/25 - Loss: 0.0176\n","Epoch 17/25 - Loss: 0.0165\n","Epoch 18/25 - Loss: 0.0148\n","Epoch 19/25 - Loss: 0.0141\n","Epoch 20/25 - Loss: 0.0129\n","Epoch 21/25 - Loss: 0.0121\n","Epoch 22/25 - Loss: 0.0112\n","Epoch 23/25 - Loss: 0.0106\n","Epoch 24/25 - Loss: 0.0099\n","Epoch 25/25 - Loss: 0.0092\n","📊 Evaluation Results - Acc: 0.950, Prec: 0.841, Rec: 0.784, F1: 0.811\n","     ➤ F1-score: 0.811, Accuracy: 0.950\n","  ▶ Training for Feature: nasal\n","Epoch 1/25 - Loss: 0.5560\n","Epoch 2/25 - Loss: 0.3060\n","Epoch 3/25 - Loss: 0.1767\n","Epoch 4/25 - Loss: 0.1015\n","Epoch 5/25 - Loss: 0.0636\n","Epoch 6/25 - Loss: 0.0438\n","Epoch 7/25 - Loss: 0.0329\n","Epoch 8/25 - Loss: 0.0268\n","Epoch 9/25 - Loss: 0.0229\n","Epoch 10/25 - Loss: 0.0201\n","Epoch 11/25 - Loss: 0.0180\n","Epoch 12/25 - Loss: 0.0162\n","Epoch 13/25 - Loss: 0.0146\n","Epoch 14/25 - Loss: 0.0134\n","Epoch 15/25 - Loss: 0.0124\n","Epoch 16/25 - Loss: 0.0115\n","Epoch 17/25 - Loss: 0.0105\n","Epoch 18/25 - Loss: 0.0097\n","Epoch 19/25 - Loss: 0.0092\n","Epoch 20/25 - Loss: 0.0084\n","Epoch 21/25 - Loss: 0.0077\n","Epoch 22/25 - Loss: 0.0072\n","Epoch 23/25 - Loss: 0.0067\n","Epoch 24/25 - Loss: 0.0061\n","Epoch 25/25 - Loss: 0.0058\n","📊 Evaluation Results - Acc: 0.970, Prec: 0.759, Rec: 0.710, F1: 0.733\n","     ➤ F1-score: 0.733, Accuracy: 0.970\n","\n","🔍 Processing Layer 11\n","  ▶ Training for Feature: voiced\n","Epoch 1/25 - Loss: 0.5718\n","Epoch 2/25 - Loss: 0.3343\n","Epoch 3/25 - Loss: 0.1789\n","Epoch 4/25 - Loss: 0.1078\n","Epoch 5/25 - Loss: 0.0767\n","Epoch 6/25 - Loss: 0.0622\n","Epoch 7/25 - Loss: 0.0539\n","Epoch 8/25 - Loss: 0.0479\n","Epoch 9/25 - Loss: 0.0435\n","Epoch 10/25 - Loss: 0.0398\n","Epoch 11/25 - Loss: 0.0366\n","Epoch 12/25 - Loss: 0.0339\n","Epoch 13/25 - Loss: 0.0315\n","Epoch 14/25 - Loss: 0.0296\n","Epoch 15/25 - Loss: 0.0276\n","Epoch 16/25 - Loss: 0.0258\n","Epoch 17/25 - Loss: 0.0241\n","Epoch 18/25 - Loss: 0.0227\n","Epoch 19/25 - Loss: 0.0214\n","Epoch 20/25 - Loss: 0.0203\n","Epoch 21/25 - Loss: 0.0191\n","Epoch 22/25 - Loss: 0.0179\n","Epoch 23/25 - Loss: 0.0170\n","Epoch 24/25 - Loss: 0.0161\n","Epoch 25/25 - Loss: 0.0152\n","📊 Evaluation Results - Acc: 0.892, Prec: 0.891, Rec: 0.909, F1: 0.900\n","     ➤ F1-score: 0.900, Accuracy: 0.892\n","  ▶ Training for Feature: fricative\n","Epoch 1/25 - Loss: 0.5803\n","Epoch 2/25 - Loss: 0.3460\n","Epoch 3/25 - Loss: 0.2027\n","Epoch 4/25 - Loss: 0.1197\n","Epoch 5/25 - Loss: 0.0748\n","Epoch 6/25 - Loss: 0.0505\n","Epoch 7/25 - Loss: 0.0380\n","Epoch 8/25 - Loss: 0.0315\n","Epoch 9/25 - Loss: 0.0268\n","Epoch 10/25 - Loss: 0.0238\n","Epoch 11/25 - Loss: 0.0213\n","Epoch 12/25 - Loss: 0.0195\n","Epoch 13/25 - Loss: 0.0178\n","Epoch 14/25 - Loss: 0.0161\n","Epoch 15/25 - Loss: 0.0148\n","Epoch 16/25 - Loss: 0.0137\n","Epoch 17/25 - Loss: 0.0128\n","Epoch 18/25 - Loss: 0.0118\n","Epoch 19/25 - Loss: 0.0109\n","Epoch 20/25 - Loss: 0.0101\n","Epoch 21/25 - Loss: 0.0094\n","Epoch 22/25 - Loss: 0.0088\n","Epoch 23/25 - Loss: 0.0081\n","Epoch 24/25 - Loss: 0.0076\n","Epoch 25/25 - Loss: 0.0071\n","📊 Evaluation Results - Acc: 0.948, Prec: 0.829, Rec: 0.784, F1: 0.806\n","     ➤ F1-score: 0.806, Accuracy: 0.948\n","  ▶ Training for Feature: nasal\n","Epoch 1/25 - Loss: 0.5279\n","Epoch 2/25 - Loss: 0.2846\n","Epoch 3/25 - Loss: 0.1551\n","Epoch 4/25 - Loss: 0.0854\n","Epoch 5/25 - Loss: 0.0514\n","Epoch 6/25 - Loss: 0.0348\n","Epoch 7/25 - Loss: 0.0264\n","Epoch 8/25 - Loss: 0.0216\n","Epoch 9/25 - Loss: 0.0183\n","Epoch 10/25 - Loss: 0.0160\n","Epoch 11/25 - Loss: 0.0141\n","Epoch 12/25 - Loss: 0.0127\n","Epoch 13/25 - Loss: 0.0114\n","Epoch 14/25 - Loss: 0.0104\n","Epoch 15/25 - Loss: 0.0093\n","Epoch 16/25 - Loss: 0.0084\n","Epoch 17/25 - Loss: 0.0077\n","Epoch 18/25 - Loss: 0.0070\n","Epoch 19/25 - Loss: 0.0064\n","Epoch 20/25 - Loss: 0.0059\n","Epoch 21/25 - Loss: 0.0054\n","Epoch 22/25 - Loss: 0.0050\n","Epoch 23/25 - Loss: 0.0046\n","Epoch 24/25 - Loss: 0.0043\n","Epoch 25/25 - Loss: 0.0040\n","📊 Evaluation Results - Acc: 0.972, Prec: 0.767, Rec: 0.742, F1: 0.754\n","     ➤ F1-score: 0.754, Accuracy: 0.972\n","\n","🔍 Processing Layer 12\n","  ▶ Training for Feature: voiced\n","Epoch 1/25 - Loss: 0.5602\n","Epoch 2/25 - Loss: 0.3056\n","Epoch 3/25 - Loss: 0.1650\n","Epoch 4/25 - Loss: 0.1083\n","Epoch 5/25 - Loss: 0.0855\n","Epoch 6/25 - Loss: 0.0730\n","Epoch 7/25 - Loss: 0.0640\n","Epoch 8/25 - Loss: 0.0585\n","Epoch 9/25 - Loss: 0.0532\n","Epoch 10/25 - Loss: 0.0495\n","Epoch 11/25 - Loss: 0.0458\n","Epoch 12/25 - Loss: 0.0431\n","Epoch 13/25 - Loss: 0.0396\n","Epoch 14/25 - Loss: 0.0374\n","Epoch 15/25 - Loss: 0.0348\n","Epoch 16/25 - Loss: 0.0326\n","Epoch 17/25 - Loss: 0.0307\n","Epoch 18/25 - Loss: 0.0288\n","Epoch 19/25 - Loss: 0.0268\n","Epoch 20/25 - Loss: 0.0255\n","Epoch 21/25 - Loss: 0.0237\n","Epoch 22/25 - Loss: 0.0226\n","Epoch 23/25 - Loss: 0.0212\n","Epoch 24/25 - Loss: 0.0200\n","Epoch 25/25 - Loss: 0.0188\n","📊 Evaluation Results - Acc: 0.873, Prec: 0.857, Rec: 0.916, F1: 0.886\n","     ➤ F1-score: 0.886, Accuracy: 0.873\n","  ▶ Training for Feature: fricative\n","Epoch 1/25 - Loss: 0.4632\n","Epoch 2/25 - Loss: 0.2444\n","Epoch 3/25 - Loss: 0.1292\n","Epoch 4/25 - Loss: 0.0754\n","Epoch 5/25 - Loss: 0.0484\n","Epoch 6/25 - Loss: 0.0366\n","Epoch 7/25 - Loss: 0.0307\n","Epoch 8/25 - Loss: 0.0277\n","Epoch 9/25 - Loss: 0.0248\n","Epoch 10/25 - Loss: 0.0224\n","Epoch 11/25 - Loss: 0.0207\n","Epoch 12/25 - Loss: 0.0190\n","Epoch 13/25 - Loss: 0.0175\n","Epoch 14/25 - Loss: 0.0165\n","Epoch 15/25 - Loss: 0.0152\n","Epoch 16/25 - Loss: 0.0145\n","Epoch 17/25 - Loss: 0.0136\n","Epoch 18/25 - Loss: 0.0126\n","Epoch 19/25 - Loss: 0.0119\n","Epoch 20/25 - Loss: 0.0113\n","Epoch 21/25 - Loss: 0.0108\n","Epoch 22/25 - Loss: 0.0099\n","Epoch 23/25 - Loss: 0.0094\n","Epoch 24/25 - Loss: 0.0088\n","Epoch 25/25 - Loss: 0.0083\n","📊 Evaluation Results - Acc: 0.957, Prec: 0.831, Rec: 0.865, F1: 0.848\n","     ➤ F1-score: 0.848, Accuracy: 0.957\n","  ▶ Training for Feature: nasal\n","Epoch 1/25 - Loss: 0.4847\n","Epoch 2/25 - Loss: 0.2169\n","Epoch 3/25 - Loss: 0.1237\n","Epoch 4/25 - Loss: 0.0668\n","Epoch 5/25 - Loss: 0.0453\n","Epoch 6/25 - Loss: 0.0346\n","Epoch 7/25 - Loss: 0.0281\n","Epoch 8/25 - Loss: 0.0242\n","Epoch 9/25 - Loss: 0.0212\n","Epoch 10/25 - Loss: 0.0190\n","Epoch 11/25 - Loss: 0.0173\n","Epoch 12/25 - Loss: 0.0157\n","Epoch 13/25 - Loss: 0.0143\n","Epoch 14/25 - Loss: 0.0131\n","Epoch 15/25 - Loss: 0.0121\n","Epoch 16/25 - Loss: 0.0111\n","Epoch 17/25 - Loss: 0.0102\n","Epoch 18/25 - Loss: 0.0094\n","Epoch 19/25 - Loss: 0.0089\n","Epoch 20/25 - Loss: 0.0083\n","Epoch 21/25 - Loss: 0.0076\n","Epoch 22/25 - Loss: 0.0069\n","Epoch 23/25 - Loss: 0.0065\n","Epoch 24/25 - Loss: 0.0061\n","Epoch 25/25 - Loss: 0.0057\n","📊 Evaluation Results - Acc: 0.970, Prec: 0.759, Rec: 0.710, F1: 0.733\n","     ➤ F1-score: 0.733, Accuracy: 0.970\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-21-e1785c8ded5e>:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  f1_df = pd.concat([f1_df, pd.DataFrame([row_f1])], ignore_index=True)\n","<ipython-input-21-e1785c8ded5e>:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  acc_df = pd.concat([acc_df, pd.DataFrame([row_acc])], ignore_index=True)\n"]},{"output_type":"stream","name":"stdout","text":["✅ F1 scores saved to: /content/drive/MyDrive/00_RESEARCH_MSC_00/Final_Phonetic_Identification/03_Evaluation_metrics_of_probes/f1_scores.csv\n","✅ Accuracy scores saved to: /content/drive/MyDrive/00_RESEARCH_MSC_00/Final_Phonetic_Identification/03_Evaluation_metrics_of_probes/accuracy_scores.csv\n","\n","✅ All layers and features have been trained, evaluated, and saved successfully.\n"]}]}]}